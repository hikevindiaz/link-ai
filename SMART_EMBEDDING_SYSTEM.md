# Smart GTE + Fallback Embedding System

## Overview

This implementation provides a sophisticated embedding system that combines the superior semantic understanding of the GTE (General Text Embeddings) model with intelligent content chunking and a reliable custom hash-based fallback system.

## Architecture

### Primary System: GTE with Intelligent Chunking
- **Model**: `gte-small` (384-dimensional transformer-based embeddings)
- **Quality**: Superior semantic understanding and contextual relationships
- **Chunking**: Intelligent content splitting that preserves semantic structure
- **Memory Management**: Optimized for Edge Function constraints

### Fallback System: Custom Hash-Based Embeddings
- **Model**: `supabase-text-embedding-v1-fallback` (384-dimensional TF-IDF style)
- **Reliability**: Always available, no external dependencies
- **Performance**: Fast generation, memory efficient
- **Quality**: Good for keyword matching and basic semantic search

## Key Components

### 1. Content Chunking (`lib/content-chunking.ts`)

Intelligent content splitting that:
- **Preserves Structure**: Keeps headings, paragraphs, and code blocks together
- **Semantic Boundaries**: Splits at natural language boundaries
- **Overlap Support**: Maintains context between chunks
- **Content-Type Optimization**: Different strategies for text, Q&A, files, websites, catalogs

```typescript
// Example usage
const chunks = chunkContent(content, {
  maxChunkSize: 1800,
  overlapSize: 200,
  preserveStructure: true,
  contentType: 'website'
});
```

#### Chunking Strategies by Content Type:

| Content Type | Max Chunk Size | Overlap | Special Handling |
|-------------|----------------|---------|------------------|
| Text | 1800 chars | 150 chars | Standard paragraph splitting |
| Q&A | 1200 chars | 100 chars | Keep questions/answers together |
| Website | 2000 chars | 200 chars | Remove navigation noise |
| File | 1600 chars | 100 chars | Preserve code structure |
| Catalog | 1000 chars | 50 chars | Keep product info together |

### 2. Enhanced Edge Function (`supabase/functions/generate-embeddings/index.ts`)

The Edge Function now includes:
- **Smart Model Selection**: Try GTE first, fallback to custom on failure
- **Memory Management**: Chunked processing with delays to prevent memory issues
- **Chunk Averaging**: Multiple chunks combined into single embedding
- **Error Handling**: Graceful degradation with detailed logging

#### Processing Flow:
1. **Content Analysis**: Determine if content needs chunking
2. **GTE Attempt**: Try processing with GTE model (up to 5 chunks)
3. **Chunk Processing**: Each chunk processed separately with small delays
4. **Embedding Averaging**: Multiple embeddings combined mathematically
5. **Fallback**: If GTE fails, use custom embedding system
6. **Metadata Tracking**: Record which model was used and performance metrics

### 3. Enhanced Vector Service (`lib/vector-service.ts`)

Improvements include:
- **Content Preprocessing**: Optimized text cleaning per content type
- **Strategy Determination**: Automatic chunking strategy selection
- **Enhanced Search**: Support for chunk grouping and filtering
- **Model Transparency**: Track and report which embedding model was used

#### Content Preprocessing:

```typescript
// Website content cleaning
processed = processed
  .replace(/^\s*(Home|Navigation|Menu|Footer|Header)\s*$/gim, '')
  .replace(/\bCopyright\s+Â©.*$/gim, '');

// Catalog content enhancement
processed = processed
  .replace(/Price:\s*\$?(\d+\.?\d*)/gi, 'Price: $$$1')
  .replace(/SKU:\s*([A-Z0-9-]+)/gi, 'Product SKU: $1');
```

### 4. Database Enhancements (`supabase/migrations/20240125_enhance_chunking_support.sql`)

New features:
- **Chunking Metadata**: Track chunk information in embedding jobs
- **Performance Indexes**: Optimized queries for chunk-related operations
- **Model Statistics**: Functions to track embedding model usage
- **Cleanup Automation**: Automatic cleanup of stale jobs

#### New Functions:
- `match_vector_documents_with_chunking()`: Enhanced search with chunk grouping
- `get_embedding_model_stats()`: Track model usage and performance
- `cleanup_stale_embedding_jobs()`: Prevent table bloat
- `get_chunking_performance()`: Performance metrics

## Benefits of This Approach

### 1. Superior RAG Quality
- **GTE Model**: Professional-grade embeddings with deep semantic understanding
- **Context Preservation**: Intelligent chunking maintains document structure
- **Chunk Overlap**: Prevents information loss at boundaries

### 2. Maximum Reliability
- **Always Available**: Fallback system ensures no embedding failures
- **Memory Safe**: Chunking prevents Edge Function memory issues
- **Error Recovery**: Graceful degradation with detailed error tracking

### 3. Performance Optimization
- **Content-Type Aware**: Different strategies for different content types
- **Noise Reduction**: Preprocessing removes irrelevant content
- **Efficient Search**: Chunk grouping reduces duplicate results

### 4. Transparency & Monitoring
- **Model Tracking**: Know which embedding model was used for each document
- **Performance Metrics**: Track processing times and success rates
- **Usage Statistics**: Monitor embedding model distribution

## Usage Examples

### Basic Content Processing
```typescript
const jobId = await processContent(
  knowledgeSourceId,
  contentId,
  'website',
  {
    content: websiteContent,
    metadata: { url: 'https://example.com' }
  }
);
```

### Enhanced Search
```typescript
const results = await searchContent(
  knowledgeSourceId,
  'machine learning algorithms',
  {
    limit: 10,
    threshold: 0.7,
    useChunking: true // Groups chunks by original content
  }
);
```

### Model Statistics
```sql
SELECT * FROM get_embedding_model_stats('knowledge-source-id');
```

## Expected Outcomes

### Model Distribution
In typical usage, you should expect:
- **70-80%** of content processed with GTE models (`gte-small`, `gte-small-chunked`)
- **20-30%** processed with fallback (`supabase-text-embedding-v1-fallback`)
- **Higher GTE usage** for smaller, well-structured content
- **More fallback usage** for very large or problematic content

### Performance Characteristics
- **GTE Processing**: 2-5 seconds per chunk (higher quality)
- **Fallback Processing**: <1 second per content (reliable)
- **Search Quality**: Significantly improved semantic matching
- **Memory Usage**: Stable, no more Edge Function crashes

## Testing

Use the test script to verify functionality:

```bash
npx tsx scripts/test-smart-embeddings.ts
```

This will test:
- Content chunking strategies
- Embedding generation with both models
- Vector search with chunk grouping
- Model statistics and performance metrics

## Migration from Previous System

### Backward Compatibility
- Existing vector documents remain functional
- Mixed embedding models supported in same knowledge base
- Search works across all embedding types

### Gradual Migration
- New content automatically uses smart system
- Existing content can be re-processed on update
- No immediate action required for existing data

## Troubleshooting

### Common Issues

1. **GTE Session Initialization Fails**
   - Check Supabase AI features are enabled
   - Verify Edge Function deployment
   - Falls back to custom embeddings automatically

2. **Memory Issues Persist**
   - Reduce max chunk size in content-chunking.ts
   - Increase delays between chunk processing
   - Check content preprocessing is working

3. **Search Quality Issues**
   - Verify content preprocessing for content type
   - Check chunk overlap settings
   - Consider re-processing with different chunking strategy

### Monitoring

Monitor the system using:
```sql
-- Check model distribution
SELECT * FROM get_embedding_model_stats();

-- Check performance metrics
SELECT * FROM get_chunking_performance();

-- Clean up stale jobs
SELECT cleanup_stale_embedding_jobs();
```

## Future Enhancements

### Potential Improvements
1. **Adaptive Chunking**: Dynamic chunk sizes based on content complexity
2. **Model Selection**: Content-type specific model preferences
3. **Batch Processing**: Multiple documents in single Edge Function call
4. **Embedding Caching**: Cache embeddings for similar content

### Advanced Features
1. **Hybrid Search**: Combine multiple embedding models in single search
2. **Quality Scoring**: Automatic quality assessment of embeddings
3. **A/B Testing**: Compare embedding models for specific content types
4. **Auto-optimization**: Automatic chunk size optimization based on performance

This system provides the best of both worlds: superior RAG quality when conditions allow, with guaranteed reliability when they don't. The intelligent chunking ensures that large content is handled gracefully while preserving semantic structure for optimal search results. 