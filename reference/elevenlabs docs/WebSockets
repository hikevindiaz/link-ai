ENDPOINTS
Text to Speech
WebSockets

GET

wss://api.elevenlabs.io
/v1/text-to-speech/:voice_id/stream-input
Handshake
URL	wss://api.elevenlabs.io/v1/text-to-speech/{voice_id}/stream-input
Method	GET
Status	101 Switching Protocols
Try it
Messages

{"text":" ","voice_settings":{"stability":0.5,"similarity_boost":0.8,"speed":1}}
publish


{"text":"Hello World","try_trigger_generation":true}
publish


{"text":""}
publish


{"audio":"Y3VyaW91cyBtaW5kcyB0aGluayBhbGlrZSA6KQ==","normalizedAlignment":{"char_start_times_ms":[0,3,7,9,11,12,13,15,17,19,21],"chars_durations_ms":[3,4,2,2,1,1,2,2,2,2,3],"chars":["H","e","l","l","o"," ","w","o","r","l","d"]},"alignment":{"char_start_times_ms":[0,3,7,9,11,12,13,15,17,19,21],"chars_durations_ms":[3,4,2,2,1,1,2,2,2,2,3],"chars":["H","e","l","l","o"," ","w","o","r","l","d"]}}
subscribe

The Text-to-Speech WebSockets API is designed to generate audio from partial text input while ensuring consistency throughout the generated audio. Although highly flexible, the WebSockets API isn’t a one-size-fits-all solution. It’s well-suited for scenarios where:

The input text is being streamed or generated in chunks.
Word-to-audio alignment information is required.
However, it may not be the best choice when:

The entire input text is available upfront. Given that the generations are partial, some buffering is involved, which could potentially result in slightly higher latency compared to a standard HTTP request.
You want to quickly experiment or prototype. Working with WebSockets can be harder and more complex than using a standard HTTP API, which might slow down rapid development and testing.
Handshake
GET

wss://api.elevenlabs.io
/v1/text-to-speech/:voice_id/stream-input

Path parameters
voice_id
string
Required
The unique identifier for the voice to use in the TTS process.

Query parameters
model_id
string
Optional
The model ID to use

language_code
string
Optional
The ISO 639-1 language code (for Turbo v2.5 and Flash v2.5 models only)

enable_logging
string
Optional
Whether to enable logging of the request

enable_ssml_parsing
boolean
Optional
Defaults to false
Whether to enable SSML parsing

optimize_streaming_latency
enum
Optional
Defaults to 0
Deprecated
Latency optimization level (deprecated)

Allowed values:
0
1
2
3
4
output_format
enum
Optional
Defaults to mp3_44100
The output audio format


Show 11 enum values
inactivity_timeout
double
Optional
Defaults to 20
Timeout for inactivity before connection is closed

sync_alignment
boolean
Optional
Defaults to false
Whether to include timing data with every audio chunk

auto_mode
boolean
Optional
Defaults to false
This parameter focuses on reducing the latency by disabling the chunk schedule and all buffers. It is only recommended when sending full sentences or phrases, sending partial phrases will result in highly reduced quality. By default it’s set to false.

apply_text_normalization
enum
Optional
Defaults to auto
This parameter controls text normalization with three modes - ‘auto’, ‘on’, and ‘off’. When set to ‘auto’, the system will automatically decide whether to apply text normalization (e.g., spelling out numbers). With ‘on’, text normalization will always be applied, while with ‘off’, it will be skipped. Cannot be turned on for ‘eleven_turbo_v2_5’ or ‘eleven_flash_v2_5’ models. Defaults to ‘auto’.

Allowed values:
auto
on
off
seed
integer
Optional
>=0
If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same seed and parameters should return the same result. Determinism is not guaranteed. Must be an integer between 0 and 4294967295.

Send
Initialize Connection
object
Required

Show 6 properties
OR
Send Text
object
Required

Show 5 properties
OR
Close Connection
object
Required

Show 1 properties
Receive
Audio Output
object
Required

Show 3 properties
OR
Final Output
object
Required

Show 1 properties